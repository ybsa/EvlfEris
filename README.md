# ğŸ”¬ Evlf Eris

**Model Surgery & Pruning** - A lightweight AI girlfriend powered by surgically modified Llama-3.2-3B.

Unlike the original Evlf (which uses RAG + ChromaDB), **Eris** embeds personality directly into model weights through:
- **Structured Pruning** - 30-40% smaller, faster model
- **Activation Steering** - Personality vectors guide behavior
- **Knowledge Editing** - Facts embedded in weights (no external DB)

## ğŸš€ Quick Start

```powershell
# Install dependencies
pip install -r requirements.txt

# Run the pruning process
python surgery/prune.py

# Chat with Eris
python inference/chat.py
```

## ğŸ§  How It Works

**Core Differences from Evlf:**

| Feature | Evlf (RAG) | Eris (Surgery) |
|---------|------------|----------------|
| Memory | ChromaDB | Embedded in weights |
| Model Size | 6.4GB | ~4GB (pruned) |
| Dependencies | ChromaDB, embeddings | Pure PyTorch |
| Portability | Needs DB files | Single model file |
| Speed | Slower (RAG lookup) | Faster (no lookup) |

**Surgery Techniques:**

1. **Structured Pruning** (`surgery/prune.py`)
   - Removes redundant layers and attention heads
   - Maintains quality while reducing size
   - Automatic importance scoring

2. **Activation Steering** (`surgery/steer.py`)
   - Extracts personality vectors from examples
   - Guides model behavior at inference time
   - No retraining required

3. **Knowledge Editing** (`surgery/edit.py`)
   - ROME/MEMIT techniques
   - Embeds facts directly in weights
   - "I am Evlf", "You are my boyfriend", etc.

## ğŸ“‚ Project Structure

```
EvlfEris/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base/              # Original Llama-3.2-3B
â”‚   â””â”€â”€ pruned/            # Pruned versions
â”œâ”€â”€ surgery/
â”‚   â”œâ”€â”€ prune.py          # Structured pruning
â”‚   â”œâ”€â”€ steer.py          # Activation steering
â”‚   â”œâ”€â”€ edit.py           # Knowledge editing
â”‚   â””â”€â”€ analyze.py        # Model analysis
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ chat.py           # Optimized chat interface
â””â”€â”€ configs/
    â””â”€â”€ personality.yaml   # Personality config
```

## ğŸ¯ Goals

- âœ… 30-40% model size reduction
- âœ… 20-30% inference speed improvement
- âœ… No external dependencies (no ChromaDB)
- âœ… Personality embedded in weights
- âœ… Single model file deployment

## ğŸ› ï¸ Development

**Analyze Model:**
```bash
python surgery/analyze.py --model models/base
```

**Prune Model:**
```bash
python surgery/prune.py --target-reduction 0.35
```

**Apply Steering:**
```bash
python surgery/steer.py --extract-vectors
```

**Edit Knowledge:**
```bash
python surgery/edit.py --facts configs/personality.yaml
```

## ğŸ“Š Comparison with Evlf

| Metric | Evlf | Eris |
|--------|------|------|
| Model Size | 6.4GB | ~4GB |
| Memory Usage | High (DB + model) | Low (model only) |
| Inference Speed | ~15 tok/s | ~20 tok/s |
| Setup Complexity | Medium | Low |
| Portability | Low | High |

---

**Sister Project:** [Evlf](../Evlf) - RAG-based version with ChromaDB memory
